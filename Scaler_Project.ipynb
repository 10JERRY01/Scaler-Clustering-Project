{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.impute import KNNImputer, SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "import scipy.cluster.hierarchy as shc\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "ppKdrLqb94XH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "DATA_FILE = 'scaler_clustering.csv'\n",
        "CURRENT_YEAR = datetime.now().year\n",
        "KNN_IMPUTE_NEIGHBORS = 5\n",
        "SAMPLE_SIZE = 5000 # Sample size for hierarchical clustering efficiency\n",
        "OPTIMAL_K = 5 # Placeholder K for K-Means (Review elbow plot after first run)\n",
        "MIN_GROUP_SIZE_FOR_RANKING = 10 # Min employees in a group for reliable Top N ranking\n",
        "MAX_YEARS_EXPERIENCE = 60 # Cap for years of experience\n",
        "MIN_VALID_YEAR = 1960 # Min valid year for 'orgyear'"
      ],
      "metadata": {
        "id": "jxHwuNfP99N7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load Data ---\n",
        "print(f\"--- 1. Loading Data from {DATA_FILE} ---\")\n",
        "try:\n",
        "    # Specify low_memory=False to potentially avoid dtype mixing warnings on large files\n",
        "    df = pd.read_csv(DATA_FILE, low_memory=False)\n",
        "    print(\"Data loaded successfully.\")\n",
        "    print(f\"Shape of the dataset: {df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {DATA_FILE}\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rLv8tUBb-DzK",
        "outputId": "d0292736-a620-4222-ca9b-d13e6151a4e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Loading Data from scaler_clustering.csv ---\n",
            "Data loaded successfully.\n",
            "Shape of the dataset: (205843, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Initial Exploratory Data Analysis (EDA) ---\n",
        "print(\"\\n--- 2. Initial Exploratory Data Analysis ---\")\n",
        "print(\"\\nDataset Info:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nStatistical Summary (Numerical):\")\n",
        "# Note: Extremely high max 'ctc' suggests potential outliers. Consider handling (e.g., capping, log transform) in future analysis.\n",
        "# Note: Min/Max 'orgyear' outside expected range indicates data quality issues. Will be handled in preprocessing.\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\nStatistical Summary (Categorical):\")\n",
        "print(df.describe(include='object'))\n",
        "\n",
        "# Check unique emails\n",
        "print(f\"\\nTotal rows: {len(df)}\")\n",
        "print(f\"Unique email_hash count: {df['email_hash'].nunique()}\")\n",
        "email_counts = df['email_hash'].value_counts()\n",
        "print(f\"Emails appearing more than once: {sum(email_counts > 1)}\")\n",
        "print(\"Top 5 most frequent email_hash:\")\n",
        "print(email_counts.head())\n",
        "\n",
        "# Check unique company_hash before cleaning\n",
        "print(f\"\\nUnique company_hash count (before cleaning): {df['company_hash'].nunique()}\")\n",
        "print(\"Top 5 company_hash values (before cleaning):\")\n",
        "print(df['company_hash'].value_counts().head())\n",
        "\n",
        "# Check unique job_position before cleaning\n",
        "print(f\"\\nUnique job_position count (before cleaning): {df['job_position'].nunique()}\")\n",
        "print(\"Top 5 job_position values (before cleaning):\")\n",
        "print(df['job_position'].value_counts().head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EvKKOu5E-NpE",
        "outputId": "b35b339d-49cc-42c9-a51b-556464457582"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 2. Initial Exploratory Data Analysis ---\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 205843 entries, 0 to 205842\n",
            "Data columns (total 7 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   Unnamed: 0        205843 non-null  int64  \n",
            " 1   company_hash      205799 non-null  object \n",
            " 2   email_hash        205843 non-null  object \n",
            " 3   orgyear           205757 non-null  float64\n",
            " 4   ctc               205843 non-null  int64  \n",
            " 5   job_position      153279 non-null  object \n",
            " 6   ctc_updated_year  205843 non-null  float64\n",
            "dtypes: float64(2), int64(2), object(3)\n",
            "memory usage: 11.0+ MB\n",
            "\n",
            "First 5 rows:\n",
            "   Unnamed: 0               company_hash  \\\n",
            "0           0             atrgxnnt xzaxv   \n",
            "1           1  qtrxvzwt xzegwgbb rxbxnta   \n",
            "2           2              ojzwnvwnxw vx   \n",
            "3           3                  ngpgutaxv   \n",
            "4           4                 qxen sqghu   \n",
            "\n",
            "                                          email_hash  orgyear      ctc  \\\n",
            "0  6de0a4417d18ab14334c3f43397fc13b30c35149d70c05...   2016.0  1100000   \n",
            "1  b0aaf1ac138b53cb6e039ba2c3d6604a250d02d5145c10...   2018.0   449999   \n",
            "2  4860c670bcd48fb96c02a4b0ae3608ae6fdd98176112e9...   2015.0  2000000   \n",
            "3  effdede7a2e7c2af664c8a31d9346385016128d66bbc58...   2017.0   700000   \n",
            "4  6ff54e709262f55cb999a1c1db8436cb2055d8f79ab520...   2017.0  1400000   \n",
            "\n",
            "         job_position  ctc_updated_year  \n",
            "0               Other            2020.0  \n",
            "1  FullStack Engineer            2019.0  \n",
            "2    Backend Engineer            2020.0  \n",
            "3    Backend Engineer            2019.0  \n",
            "4  FullStack Engineer            2019.0  \n",
            "\n",
            "Statistical Summary (Numerical):\n",
            "          Unnamed: 0        orgyear           ctc  ctc_updated_year\n",
            "count  205843.000000  205757.000000  2.058430e+05     205843.000000\n",
            "mean   103273.941786    2014.882750  2.271685e+06       2019.628231\n",
            "std     59741.306484      63.571115  1.180091e+07          1.325104\n",
            "min         0.000000       0.000000  2.000000e+00       2015.000000\n",
            "25%     51518.500000    2013.000000  5.300000e+05       2019.000000\n",
            "50%    103151.000000    2016.000000  9.500000e+05       2020.000000\n",
            "75%    154992.500000    2018.000000  1.700000e+06       2021.000000\n",
            "max    206922.000000   20165.000000  1.000150e+09       2021.000000\n",
            "\n",
            "Statistical Summary (Categorical):\n",
            "                     company_hash  \\\n",
            "count                      205799   \n",
            "unique                      37299   \n",
            "top     nvnv wgzohrnvzwj otqcxwto   \n",
            "freq                         8337   \n",
            "\n",
            "                                               email_hash      job_position  \n",
            "count                                              205843            153279  \n",
            "unique                                             153443              1016  \n",
            "top     bbace3cc586400bbc65765bc6a16b77d8913836cfc98b7...  Backend Engineer  \n",
            "freq                                                   10             43554  \n",
            "\n",
            "Total rows: 205843\n",
            "Unique email_hash count: 153443\n",
            "Emails appearing more than once: 41216\n",
            "Top 5 most frequent email_hash:\n",
            "email_hash\n",
            "bbace3cc586400bbc65765bc6a16b77d8913836cfc98b77c05488f02f5714a4b    10\n",
            "3e5e49daa5527a6d5a33599b238bf9bf31e85b9efa9a94f1c88c5e15a6f31378     9\n",
            "298528ce3160cc761e4dc37a07337ee2e0589df251d73645aae209b010210eee     9\n",
            "6842660273f70e9aa239026ba33bfe82275d6ab0d20124021b952b5bc3d07e6c     9\n",
            "d598d6f1fb21b45593c2afc1c2f76ae9f4cb7167156cdf93246d4192a89d8065     8\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique company_hash count (before cleaning): 37299\n",
            "Top 5 company_hash values (before cleaning):\n",
            "company_hash\n",
            "nvnv wgzohrnvzwj otqcxwto    8337\n",
            "xzegojo                      5381\n",
            "vbvkgz                       3481\n",
            "zgn vuurxwvmrt vwwghzn       3411\n",
            "wgszxkvzn                    3240\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique job_position count (before cleaning): 1016\n",
            "Top 5 job_position values (before cleaning):\n",
            "job_position\n",
            "Backend Engineer          43554\n",
            "FullStack Engineer        24717\n",
            "Other                     18071\n",
            "Frontend Engineer         10417\n",
            "Engineering Leadership     6870\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Data Pre-processing ---\n",
        "print(\"\\n--- 3. Data Pre-processing ---\")\n",
        "\n",
        "# Drop the 'Unnamed: 0' column if it exists and is just an index\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    print(\"\\nDropping 'Unnamed: 0' column.\")\n",
        "    df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "\n",
        "# Handle Missing Values & Clean Text Columns\n",
        "print(\"\\nChecking for missing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"\\nCleaning 'company_hash' and 'job_position'...\")\n",
        "df['company_hash'].fillna('Unknown_Company', inplace=True)\n",
        "df['job_position'].fillna('Unknown_Position', inplace=True)\n",
        "\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = re.sub(r'[^\\w\\s]', '', text) # Keep alphanumeric and whitespace\n",
        "        text = text.strip().lower()\n",
        "        text = re.sub(r'\\s+', ' ', text) # Consolidate whitespace\n",
        "    return text\n",
        "\n",
        "df['Company_hash_Cleaned'] = df['company_hash'].apply(clean_text)\n",
        "df['Job_position_Cleaned'] = df['job_position'].apply(clean_text)\n",
        "# Replace potentially empty strings after cleaning\n",
        "df['Company_hash_Cleaned'].replace('', 'unknown_company', inplace=True)\n",
        "df['Job_position_Cleaned'].replace('', 'unknown_position', inplace=True)\n",
        "\n",
        "print(f\"\\nUnique Company_hash count (after cleaning): {df['Company_hash_Cleaned'].nunique()}\")\n",
        "print(f\"Unique Job_position count (after cleaning): {df['Job_position_Cleaned'].nunique()}\")\n",
        "\n",
        "# Handle Data Types and Impute 'orgyear'\n",
        "print(\"\\nProcessing numerical columns and imputing 'orgyear'...\")\n",
        "df['ctc'] = pd.to_numeric(df['ctc'], errors='coerce')\n",
        "df['ctc_updated_year'] = pd.to_numeric(df['ctc_updated_year'], errors='coerce')\n",
        "df['orgyear'] = pd.to_numeric(df['orgyear'], errors='coerce')\n",
        "\n",
        "# --- Handle invalid 'orgyear' values before imputation ---\n",
        "# Set years outside a reasonable range (e.g., 1960-CurrentYear) to NaN\n",
        "df.loc[(df['orgyear'] < MIN_VALID_YEAR) | (df['orgyear'] > CURRENT_YEAR), 'orgyear'] = np.nan\n",
        "print(f\"\\nSet 'orgyear' outside {MIN_VALID_YEAR}-{CURRENT_YEAR} to NaN.\")\n",
        "\n",
        "print(\"\\nMissing values before imputation (ctc, orgyear):\")\n",
        "print(df[['ctc', 'orgyear']].isnull().sum())\n",
        "\n",
        "# Impute ctc first if needed (median)\n",
        "if df['ctc'].isnull().any():\n",
        "    print(\"\\nImputing missing ctc values using median...\")\n",
        "    # Note: Imputing CTC outliers with median might still leave skewed distribution. Consider capping or log transform for future analysis.\n",
        "    median_imputer_ctc = SimpleImputer(strategy='median')\n",
        "    df['ctc'] = median_imputer_ctc.fit_transform(df[['ctc']])\n",
        "    print(\"ctc imputation done.\")\n",
        "\n",
        "# Impute orgyear using KNN based on ctc\n",
        "if df['orgyear'].isnull().any():\n",
        "    print(f\"\\nImputing missing 'orgyear' values using KNNImputer (k={KNN_IMPUTE_NEIGHBORS})...\")\n",
        "    impute_features = ['ctc', 'orgyear']\n",
        "    df_impute = df[impute_features].copy()\n",
        "    # Scale before KNN\n",
        "    scaler_impute = StandardScaler()\n",
        "    df_impute_scaled = scaler_impute.fit_transform(df_impute)\n",
        "    # KNN Imputation\n",
        "    knn_imputer = KNNImputer(n_neighbors=KNN_IMPUTE_NEIGHBORS)\n",
        "    df_impute_imputed_scaled = knn_imputer.fit_transform(df_impute_scaled)\n",
        "    # Inverse scale\n",
        "    df_impute_imputed = scaler_impute.inverse_transform(df_impute_imputed_scaled)\n",
        "    # Update orgyear, ensuring it's integer\n",
        "    df['orgyear'] = df_impute_imputed[:, impute_features.index('orgyear')].round().astype(int)\n",
        "    print(\"orgyear imputation done.\")\n",
        "else:\n",
        "    print(\"\\nNo missing 'orgyear' values to impute after initial cleaning.\")\n",
        "\n",
        "# Ensure orgyear is integer type after potential imputation\n",
        "df['orgyear'] = df['orgyear'].astype(int)\n",
        "\n",
        "print(\"\\nMissing values after imputation (ctc, orgyear):\")\n",
        "print(df[['ctc', 'orgyear']].isnull().sum()) # Should be 0\n",
        "\n",
        "# Remove Duplicates (based on all columns)\n",
        "print(\"\\nChecking for duplicate rows...\")\n",
        "initial_rows = len(df)\n",
        "# Consider which columns define a true duplicate. Using all columns for now.\n",
        "df.drop_duplicates(inplace=True)\n",
        "final_rows = len(df)\n",
        "print(f\"Removed {initial_rows - final_rows} duplicate rows.\")\n",
        "print(f\"Shape after dropping duplicates: {df.shape}\")\n",
        "\n",
        "# Feature Engineering: Years of Experience\n",
        "print(\"\\nCreating 'Years_of_Experience' feature...\")\n",
        "df['Years_of_Experience'] = CURRENT_YEAR - df['orgyear']\n",
        "# Cap experience to handle potential remaining issues from imputation or original data\n",
        "df['Years_of_Experience'] = df['Years_of_Experience'].apply(lambda x: min(max(0, x), MAX_YEARS_EXPERIENCE))\n",
        "print(f\"Capped 'Years_of_Experience' at {MAX_YEARS_EXPERIENCE} years.\")\n",
        "print(df[['orgyear', 'Years_of_Experience']].head())\n",
        "print(\"\\nYears_of_Experience summary (after capping):\")\n",
        "print(df['Years_of_Experience'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AogtAkQx-Ody",
        "outputId": "0d9315c5-0720-45d8-bf6b-bba81fdf744b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 3. Data Pre-processing ---\n",
            "\n",
            "Dropping 'Unnamed: 0' column.\n",
            "\n",
            "Checking for missing values:\n",
            "company_hash           44\n",
            "email_hash              0\n",
            "orgyear                86\n",
            "ctc                     0\n",
            "job_position        52564\n",
            "ctc_updated_year        0\n",
            "dtype: int64\n",
            "\n",
            "Cleaning 'company_hash' and 'job_position'...\n",
            "\n",
            "Unique Company_hash count (after cleaning): 37228\n",
            "Unique Job_position count (after cleaning): 885\n",
            "\n",
            "Processing numerical columns and imputing 'orgyear'...\n",
            "\n",
            "Set 'orgyear' outside 1960-2025 to NaN.\n",
            "\n",
            "Missing values before imputation (ctc, orgyear):\n",
            "ctc          0\n",
            "orgyear    160\n",
            "dtype: int64\n",
            "\n",
            "Imputing missing 'orgyear' values using KNNImputer (k=5)...\n",
            "orgyear imputation done.\n",
            "\n",
            "Missing values after imputation (ctc, orgyear):\n",
            "ctc        0\n",
            "orgyear    0\n",
            "dtype: int64\n",
            "\n",
            "Checking for duplicate rows...\n",
            "Removed 34 duplicate rows.\n",
            "Shape after dropping duplicates: (205809, 8)\n",
            "\n",
            "Creating 'Years_of_Experience' feature...\n",
            "Capped 'Years_of_Experience' at 60 years.\n",
            "   orgyear  Years_of_Experience\n",
            "0     2016                    9\n",
            "1     2018                    7\n",
            "2     2015                   10\n",
            "3     2017                    8\n",
            "4     2017                    8\n",
            "\n",
            "Years_of_Experience summary (after capping):\n",
            "count    205809.000000\n",
            "mean          9.883664\n",
            "std           4.233612\n",
            "min           0.000000\n",
            "25%           7.000000\n",
            "50%           9.000000\n",
            "75%          12.000000\n",
            "max          55.000000\n",
            "Name: Years_of_Experience, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Further EDA (Post Pre-processing) ---\n",
        "print(\"\\n--- 4. Further EDA (Post Pre-processing) ---\")\n",
        "# Plotting distributions and relationships\n",
        "numerical_cols = ['ctc', 'Years_of_Experience', 'ctc_updated_year']\n",
        "print(\"\\nGenerating distribution plots...\")\n",
        "for col in numerical_cols:\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        # Use log scale for CTC as it's highly skewed\n",
        "        if col == 'ctc':\n",
        "            # Filter out non-positive values for log scale if any exist after cleaning\n",
        "            plot_data = df[df[col] > 0][col].dropna()\n",
        "            if not plot_data.empty:\n",
        "                sns.histplot(plot_data, kde=True, log_scale=True)\n",
        "                plt.title(f'Distribution of {col} (Log Scale)')\n",
        "            else:\n",
        "                plt.title(f'Distribution of {col} (No positive data for log scale)')\n",
        "        else:\n",
        "            plot_data = df[col].dropna()\n",
        "            if not plot_data.empty:\n",
        "                sns.histplot(plot_data, kde=True)\n",
        "                plt.title(f'Distribution of {col}')\n",
        "            else:\n",
        "                 plt.title(f'Distribution of {col} (No data)')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'dist_{col}.png')\n",
        "        plt.close()\n",
        "        print(f\"Saved distribution plot for {col} as dist_{col}.png\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate distribution plot for {col}: {e}\")\n",
        "\n",
        "categorical_cols = ['Company_hash_Cleaned', 'Job_position_Cleaned']\n",
        "print(\"\\nGenerating count plots for top N categorical features...\")\n",
        "N_TOP = 20\n",
        "for col in categorical_cols:\n",
        "    try:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        # Ensure the column exists and has data\n",
        "        if col in df.columns and not df[col].empty:\n",
        "            top_categories = df[col].value_counts().nlargest(N_TOP).index\n",
        "            if not top_categories.empty:\n",
        "                sns.countplot(y=df[df[col].isin(top_categories)][col], order=top_categories)\n",
        "                plt.title(f'Top {N_TOP} Categories in {col}')\n",
        "            else:\n",
        "                plt.title(f'No top categories found for {col}')\n",
        "        else:\n",
        "            plt.title(f'Column {col} not found or empty')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'count_{col}.png')\n",
        "        plt.close()\n",
        "        print(f\"Saved count plot for {col} as count_{col}.png\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate count plot for {col}: {e}\")\n",
        "\n",
        "print(\"\\nGenerating Bivariate Analysis (Experience vs ctc)...\")\n",
        "try:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    # Sample data for scatter plot if too large\n",
        "    sample_df_scatter = df.sample(n=min(50000, len(df)), random_state=42) if len(df) > 50000 else df\n",
        "    # Filter out non-positive CTC for log scale\n",
        "    plot_data_scatter = sample_df_scatter[sample_df_scatter['ctc'] > 0]\n",
        "    if not plot_data_scatter.empty:\n",
        "        sns.scatterplot(data=plot_data_scatter, x='Years_of_Experience', y='ctc', alpha=0.3)\n",
        "        plt.yscale('log') # Apply log scale to y-axis\n",
        "        plt.title('Years of Experience vs ctc (Sampled, Log Scale)')\n",
        "    else:\n",
        "        plt.title('Years of Experience vs ctc (No positive ctc data for log scale)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('bivariate_exp_ctc.png')\n",
        "    plt.close()\n",
        "    print(\"Saved scatter plot for Experience vs ctc as bivariate_exp_ctc.png\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not generate scatter plot: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CaSfnOdT-pN-",
        "outputId": "e578db6b-82de-4de7-f992-924d4eae8852"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 4. Further EDA (Post Pre-processing) ---\n",
            "\n",
            "Generating distribution plots...\n",
            "Saved distribution plot for ctc as dist_ctc.png\n",
            "Saved distribution plot for Years_of_Experience as dist_Years_of_Experience.png\n",
            "Saved distribution plot for ctc_updated_year as dist_ctc_updated_year.png\n",
            "\n",
            "Generating count plots for top N categorical features...\n",
            "Saved count plot for Company_hash_Cleaned as count_Company_hash_Cleaned.png\n",
            "Saved count plot for Job_position_Cleaned as count_Job_position_Cleaned.png\n",
            "\n",
            "Generating Bivariate Analysis (Experience vs ctc)...\n",
            "Saved scatter plot for Experience vs ctc as bivariate_exp_ctc.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Manual Clustering ---\n",
        "print(\"\\n--- 5. Manual Clustering ---\")\n",
        "print(\"\\nCalculating ctc summaries...\")\n",
        "# Calculate summaries (mean, median, etc.)\n",
        "summary_co_job_exp = df.groupby(['Company_hash_Cleaned', 'Job_position_Cleaned', 'Years_of_Experience'])['ctc'].agg(['mean', 'median', 'max', 'min', 'count']).reset_index()\n",
        "summary_co_job_exp.rename(columns={'mean': 'Avg_ctc_Co_Job_Exp', 'median': 'Median_ctc_Co_Job_Exp', 'max': 'Max_ctc_Co_Job_Exp', 'min': 'Min_ctc_Co_Job_Exp', 'count': 'Count_Co_Job_Exp'}, inplace=True)\n",
        "summary_co_job = df.groupby(['Company_hash_Cleaned', 'Job_position_Cleaned'])['ctc'].agg(['mean', 'median', 'max', 'min', 'count']).reset_index()\n",
        "summary_co_job.rename(columns={'mean': 'Avg_ctc_Co_Job', 'median': 'Median_ctc_Co_Job', 'max': 'Max_ctc_Co_Job', 'min': 'Min_ctc_Co_Job', 'count': 'Count_Co_Job'}, inplace=True)\n",
        "summary_co = df.groupby(['Company_hash_Cleaned'])['ctc'].agg(['mean', 'median', 'max', 'min', 'count']).reset_index()\n",
        "summary_co.rename(columns={'mean': 'Avg_ctc_Co', 'median': 'Median_ctc_Co', 'max': 'Max_ctc_Co', 'min': 'Min_ctc_Co', 'count': 'Count_Co'}, inplace=True)\n",
        "\n",
        "print(\"\\nMerging summaries with the main dataframe...\")\n",
        "df = pd.merge(df, summary_co_job_exp, on=['Company_hash_Cleaned', 'Job_position_Cleaned', 'Years_of_Experience'], how='left')\n",
        "df = pd.merge(df, summary_co_job, on=['Company_hash_Cleaned', 'Job_position_Cleaned'], how='left')\n",
        "df = pd.merge(df, summary_co, on=['Company_hash_Cleaned'], how='left')\n",
        "print(\"Merging complete.\")\n",
        "\n",
        "# Create Flags (Designation, Class, Tier)\n",
        "print(\"\\nCreating manual clustering flags...\")\n",
        "# Ensure comparison columns are numeric before creating flags\n",
        "for col in ['ctc', 'Avg_ctc_Co_Job_Exp', 'Avg_ctc_Co_Job', 'Avg_ctc_Co']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "df['Designation'] = np.select([df['ctc'] > df['Avg_ctc_Co_Job_Exp'], df['ctc'] == df['Avg_ctc_Co_Job_Exp']], [1, 2], default=3)\n",
        "df['Designation'] = df['Designation'].where(df['Avg_ctc_Co_Job_Exp'].notna() & df['ctc'].notna(), other=2) # Handle NaN averages or ctc\n",
        "df['Class'] = np.select([df['ctc'] > df['Avg_ctc_Co_Job'], df['ctc'] == df['Avg_ctc_Co_Job']], [1, 2], default=3)\n",
        "df['Class'] = df['Class'].where(df['Avg_ctc_Co_Job'].notna() & df['ctc'].notna(), other=2)\n",
        "df['Tier'] = np.select([df['ctc'] > df['Avg_ctc_Co'], df['ctc'] == df['Avg_ctc_Co']], [1, 2], default=3)\n",
        "df['Tier'] = df['Tier'].where(df['Avg_ctc_Co'].notna() & df['ctc'].notna(), other=2)\n",
        "print(\"Flags created (Designation, Class, Tier).\")\n",
        "print(df[['Designation', 'Class', 'Tier']].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PLwj0k53-vES",
        "outputId": "0a39c165-7524-4d21-f154-0cdfe5e11e85"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 5. Manual Clustering ---\n",
            "\n",
            "Calculating ctc summaries...\n",
            "\n",
            "Merging summaries with the main dataframe...\n",
            "Merging complete.\n",
            "\n",
            "Creating manual clustering flags...\n",
            "Flags created (Designation, Class, Tier).\n",
            "Designation  Class  Tier\n",
            "3            3      3       63426\n",
            "2            2      2       33069\n",
            "             3      3       18558\n",
            "1            1      1       16855\n",
            "             3      3       16074\n",
            "2            2      3       12948\n",
            "             1      1       12137\n",
            "             2      1        9521\n",
            "1            1      3        7942\n",
            "2            1      3        5571\n",
            "3            1      1        2545\n",
            "                    3        2366\n",
            "2            3      1        2104\n",
            "3            3      1        1311\n",
            "1            3      1        1293\n",
            "3            2      3          22\n",
            "1            2      3          18\n",
            "                    1          16\n",
            "3            2      1          11\n",
            "2            1      2          10\n",
            "             3      2           7\n",
            "1            1      2           2\n",
            "3            1      2           1\n",
            "             2      2           1\n",
            "             3      2           1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Answering Questions based on Manual Clustering ---\n",
        "print(\"\\n--- 6. Answering Questions based on Manual Clustering ---\")\n",
        "df_results = df[['email_hash', 'Company_hash_Cleaned', 'Job_position_Cleaned', 'Years_of_Experience', 'ctc', 'Designation', 'Class', 'Tier']].copy()\n",
        "df_results.sort_values(by='ctc', ascending=False, inplace=True)\n",
        "\n",
        "# Top/Bottom Employees based on Tier\n",
        "top_tier1 = df_results[df_results['Tier'] == 1].head(10)\n",
        "print(\"\\nTop 10 Employees (Overall High Earners within Company - Tier 1):\")\n",
        "print(top_tier1)\n",
        "bottom_tier3 = df_results[df_results['Tier'] == 3].sort_values(by='ctc', ascending=True).head(10)\n",
        "print(\"\\nBottom 10 Employees (Overall Low Earners within Company - Tier 3):\")\n",
        "print(bottom_tier3)\n",
        "\n",
        "# Data Science Roles Analysis based on Class\n",
        "ds_positions = df_results[df_results['Job_position_Cleaned'].str.contains('data scientist|data science', case=False, na=False)]\n",
        "if not ds_positions.empty:\n",
        "    top_ds_class1 = ds_positions[ds_positions['Class'] == 1].sort_values(['Company_hash_Cleaned', 'ctc'], ascending=[True, False]).groupby('Company_hash_Cleaned').head(10)\n",
        "    print(\"\\nTop 10 Data Science Employees per Company (High Earners within Job - Class 1):\")\n",
        "    print(top_ds_class1)\n",
        "    bottom_ds_class3 = ds_positions[ds_positions['Class'] == 3].sort_values(['Company_hash_Cleaned', 'ctc'], ascending=[True, True]).groupby('Company_hash_Cleaned').head(10)\n",
        "    print(\"\\nBottom 10 Data Science Employees per Company (Low Earners within Job - Class 3):\")\n",
        "    print(bottom_ds_class3)\n",
        "else:\n",
        "    print(\"\\nNo 'Data Science' positions found for Class analysis.\")\n",
        "\n",
        "# Specific Role/Experience Analysis based on Designation\n",
        "exp_filter = 5\n",
        "job_filter = 'software engineer'\n",
        "top_specific_designation1 = df_results[(df_results['Job_position_Cleaned'] == job_filter) & (df_results['Years_of_Experience'] == exp_filter) & (df_results['Designation'] == 1)].sort_values(['Company_hash_Cleaned', 'ctc'], ascending=[True, False]).groupby('Company_hash_Cleaned').head(10)\n",
        "print(f\"\\nTop 10 '{job_filter}' Employees per Company with {exp_filter} YoE (High Earners within Specific Group - Designation 1):\")\n",
        "print(top_specific_designation1)\n",
        "\n",
        "# Top Companies/Positions based on Average CTC (with min size filter)\n",
        "print(f\"\\nCalculating Top Companies/Positions based on groups with at least {MIN_GROUP_SIZE_FOR_RANKING} employees...\")\n",
        "reliable_summary_co = summary_co[summary_co['Count_Co'] >= MIN_GROUP_SIZE_FOR_RANKING]\n",
        "top_companies_avg_ctc = reliable_summary_co.sort_values('Avg_ctc_Co', ascending=False).head(10)\n",
        "print(\"\\nTop 10 Companies (by Average ctc, min size applied):\")\n",
        "print(top_companies_avg_ctc[['Company_hash_Cleaned', 'Avg_ctc_Co', 'Count_Co']])\n",
        "\n",
        "reliable_summary_co_job = summary_co_job[summary_co_job['Count_Co_Job'] >= MIN_GROUP_SIZE_FOR_RANKING]\n",
        "top_positions_per_company = reliable_summary_co_job.sort_values(['Company_hash_Cleaned', 'Avg_ctc_Co_Job'], ascending=[True, False]).groupby('Company_hash_Cleaned').head(2)\n",
        "print(\"\\nTop 2 Positions per Company (by Average ctc, min size applied):\")\n",
        "print(top_positions_per_company[['Company_hash_Cleaned', 'Job_position_Cleaned', 'Avg_ctc_Co_Job', 'Count_Co_Job']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YxLxGAsA-zYf",
        "outputId": "27109b60-9e67-4bd4-d6e7-5ecb48a9b974"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 6. Answering Questions based on Manual Clustering ---\n",
            "\n",
            "Top 10 Employees (Overall High Earners within Company - Tier 1):\n",
            "                                               email_hash  \\\n",
            "117626  5b4bed51797140db4ed52018a979db1e34cee49e27b488...   \n",
            "10664   4b5dcb53e770840247f358d642ecdf65891556ece4a5a2...   \n",
            "3311    331f1c3d933482a7d0bfe778e8d4e85aa969742ed24bbf...   \n",
            "9550    85c1eb396246a8f61b82ec558d6e322efd23a762af856c...   \n",
            "10659   853731bca9459bfff54bf61518885293a0f4a8bef6fca6...   \n",
            "31963   fe2c448bc7d2b5a523864ef3a4bc5d4b3f3af390a66984...   \n",
            "66364   f5b2a30853a67e1703249db6003884d7e1ae69e0c03aa0...   \n",
            "9609    9e785d33821db67c01becc1c36f901d79d3142c1d13bd8...   \n",
            "21543   35d4845547c5d2e0c2eadc197c97c678035bceb5fddd2d...   \n",
            "21462   979235a69267e855c0361f670e5941138307caf43fa986...   \n",
            "\n",
            "             Company_hash_Cleaned    Job_position_Cleaned  \\\n",
            "117626               obvqnuqxdwgb        unknown_position   \n",
            "10664                     xzegojo                   other   \n",
            "3311                        tvngz      engineering intern   \n",
            "9550                ntwy bvyxzaqv  engineering leadership   \n",
            "10659                   qtexzxnxc            data analyst   \n",
            "31963                  eqttrvzwtq                   other   \n",
            "66364                ogwxn szqvrt        unknown_position   \n",
            "9609                       vbvkgz        unknown_position   \n",
            "21543                         qmo            data analyst   \n",
            "21462   nvnv wgzohrnvzwj otqcxwto        support engineer   \n",
            "\n",
            "        Years_of_Experience        ctc  Designation  Class  Tier  \n",
            "117626                    7  255555555            1      1     1  \n",
            "10664                    10  200000000            1      1     1  \n",
            "3311                     12  200000000            2      2     1  \n",
            "9550                      3  200000000            2      1     1  \n",
            "10659                     7  200000000            2      1     1  \n",
            "31963                     3  200000000            1      1     1  \n",
            "66364                    11  200000000            1      1     1  \n",
            "9609                      8  200000000            1      1     1  \n",
            "21543                    10  200000000            1      1     1  \n",
            "21462                     7  200000000            1      1     1  \n",
            "\n",
            "Bottom 10 Employees (Overall Low Earners within Company - Tier 3):\n",
            "                                               email_hash  \\\n",
            "135421  3505b02549ebe2c95840ac6f0a35561a3b4cbe4b79cdb1...   \n",
            "118226  f2b58aeed3c074652de2cfd3c0717a5d21d6fbcf342a78...   \n",
            "114157  23ad96d6b6f1ecf554a52f6e9b61677c7d73d8a409a143...   \n",
            "184918  b8a0bb340583936b5a7923947e9aec21add5ebc50cd60b...   \n",
            "116938  f7e5e788676100d7c4146740ada9e2f8974defc01f571d...   \n",
            "99417   b995d7a2ae5c6f8497762ce04dc5c04ad6ec734d70802a...   \n",
            "150664  9af3dca6c9d705d8d42585ccfce2627f00e1629130d14e...   \n",
            "171173  80ba0259f9f59034c4927cf3bd38dc9ce2eb60ff18135b...   \n",
            "83644   a7894c6d848de3021cfd16b35178cf8f48b10d77aa46dc...   \n",
            "93121   4ea8ce7809d8c69147d243bad53d88d016a1151690b8b6...   \n",
            "\n",
            "             Company_hash_Cleaned    Job_position_Cleaned  \\\n",
            "135421               xzntqcxtfmxn        backend engineer   \n",
            "118226               xzntqcxtfmxn        unknown_position   \n",
            "114157               xzntqcxtfmxn        unknown_position   \n",
            "184918                         xm        unknown_position   \n",
            "116938   hzxctqoxnj ge fvoyxzsngz        unknown_position   \n",
            "99417                         gjg      fullstack engineer   \n",
            "150664                        zvz        unknown_position   \n",
            "171173  nvnv wgzohrnvzwj otqcxwto        backend engineer   \n",
            "83644          bgngqgrv ogrhnxgzo        android engineer   \n",
            "93121                         zvz  engineering leadership   \n",
            "\n",
            "        Years_of_Experience   ctc  Designation  Class  Tier  \n",
            "135421                   11     2            3      3     3  \n",
            "118226                   12     6            3      3     3  \n",
            "114157                   12    14            1      3     3  \n",
            "184918                    9    15            2      3     3  \n",
            "116938                    3   200            2      2     3  \n",
            "99417                     7   600            3      3     3  \n",
            "150664                    2   600            3      3     3  \n",
            "171173                   13   600            3      3     3  \n",
            "83644                     9  1000            2      3     3  \n",
            "93121                    15  1000            2      3     3  \n",
            "\n",
            "Top 10 Data Science Employees per Company (High Earners within Job - Class 1):\n",
            "                                               email_hash  \\\n",
            "139665  6b01808bba4c2d50258b068274232251620630cb252a9c...   \n",
            "142687  9d2537610d57179230806bb77258f63c3134b8fde9aa3a...   \n",
            "90218   ddd9683a58865398ed934ee7faeb0825e515f2fe3cdaad...   \n",
            "164811  af617ba27ec944771314f1c2d739b8208d2b3337800f8f...   \n",
            "105828  a372713f7d18e6f03b5b469cbd1ddb8145c2688597c528...   \n",
            "...                                                   ...   \n",
            "130033  007d0b8b8b80245cba5c804d64d4fa9fd14b4d2e92acdf...   \n",
            "130585  56bc8f0eb4db04e459bf41f51c12b3bbb9c3595d8a172d...   \n",
            "71179   9be05cb8d1f11aa76fb01b9e33ff5633efb82fb22e085f...   \n",
            "111060  032d8bf5403336d4a5fc081dc72a6eba716990886a02d3...   \n",
            "158976  1cd0a52ed52dae24d605d9cdc8536499c10ce62bfb070f...   \n",
            "\n",
            "              Company_hash_Cleaned Job_position_Cleaned  Years_of_Experience  \\\n",
            "139665                         1bs       data scientist                    7   \n",
            "142687                       247vx       data scientist                   15   \n",
            "90218                        247vx       data scientist                   17   \n",
            "164811             3p ntwyzgrgsxto       data scientist                    7   \n",
            "105828                        3rgi       data scientist                   11   \n",
            "...                            ...                  ...                  ...   \n",
            "130033  zxwt xzntqvwnxct ogrhnxgzo       data scientist                   12   \n",
            "130585           zxxn ntwyzgrgsxto       data scientist                   18   \n",
            "71179    zxxn ntwyzgrgsxto rxbxnta       data scientist                   10   \n",
            "111060   zxxn ntwyzgrgsxto rxbxnta       data scientist                   11   \n",
            "158976                   zxztrtvuo       data scientist                   11   \n",
            "\n",
            "            ctc  Designation  Class  Tier  \n",
            "139665  1100000            2      1     3  \n",
            "142687  2600000            2      1     1  \n",
            "90218   2500000            2      1     1  \n",
            "164811  1800000            1      1     1  \n",
            "105828  1710000            2      1     1  \n",
            "...         ...          ...    ...   ...  \n",
            "130033  1130000            2      1     3  \n",
            "130585  5500000            2      1     1  \n",
            "71179   1500000            2      1     3  \n",
            "111060  1200000            2      1     3  \n",
            "158976  2250000            2      1     1  \n",
            "\n",
            "[1264 rows x 8 columns]\n",
            "\n",
            "Bottom 10 Data Science Employees per Company (Low Earners within Job - Class 3):\n",
            "                                               email_hash  \\\n",
            "177938  eb213c0552effd7fb139395c7838edb8d59773a1cb57a0...   \n",
            "150262  5f4b52a1c2539fe2e4b29a8470bc57dbace331b819a0af...   \n",
            "71570   c35054c043f6a02da3e6f142fbcb095f8145eb521137ff...   \n",
            "159892  89901f32acc07b5ca10c4ee5a9afda6de831cb84a0cbeb...   \n",
            "84265   f3b1e96456ad8a7d9cceb3901d763252ea2f56eb2ee7f4...   \n",
            "...                                                   ...   \n",
            "148978  1aa2717970a46b5d12b90932799227774dd418c842fa18...   \n",
            "103131  5ab93fd511bceaa6da5f855d160de306a04df9951f5978...   \n",
            "51679   f678c67bee8cad9370f6aaf4f4cc22ffd417fd753663c6...   \n",
            "130909  3027ca561b65f99da2f65bf3d85c6bb5d5687c67e69e89...   \n",
            "192832  10d566c5fca40ffe1d133b79594d071880711ef480da9f...   \n",
            "\n",
            "             Company_hash_Cleaned Job_position_Cleaned  Years_of_Experience  \\\n",
            "177938                        1bs       data scientist                   31   \n",
            "150262                      247vx       data scientist                   23   \n",
            "71570                       247vx       data scientist                   11   \n",
            "159892            3p ntwyzgrgsxto       data scientist                    6   \n",
            "84265             3p ntwyzgrgsxto       data scientist                   12   \n",
            "...                           ...                  ...                  ...   \n",
            "148978          zxxn ntwyzgrgsxto       data scientist                   13   \n",
            "103131  zxxn ntwyzgrgsxto rxbxnta       data scientist                   13   \n",
            "51679                   zxztrtvuo       data scientist                    6   \n",
            "130909                  zxztrtvuo       data scientist                    7   \n",
            "192832                  zxztrtvuo       data scientist                    8   \n",
            "\n",
            "            ctc  Designation  Class  Tier  \n",
            "177938   800000            2      3     3  \n",
            "150262  1440000            2      3     3  \n",
            "71570   2150000            2      3     1  \n",
            "159892  1000000            2      3     3  \n",
            "84265   1200000            2      3     1  \n",
            "...         ...          ...    ...   ...  \n",
            "148978  2200000            2      3     1  \n",
            "103131   800000            2      3     3  \n",
            "51679   1250000            2      3     1  \n",
            "130909  1370000            2      3     1  \n",
            "192832  1400000            2      3     1  \n",
            "\n",
            "[1531 rows x 8 columns]\n",
            "\n",
            "Top 10 'software engineer' Employees per Company with 5 YoE (High Earners within Specific Group - Designation 1):\n",
            "                                              email_hash Company_hash_Cleaned  \\\n",
            "85588  46aace1ee4bd2ece8d1cd4f0d48d3bc7db26fb4b971395...              gzturho   \n",
            "\n",
            "      Job_position_Cleaned  Years_of_Experience      ctc  Designation  Class  \\\n",
            "85588    software engineer                    5  1360000            1      1   \n",
            "\n",
            "       Tier  \n",
            "85588     3  \n",
            "\n",
            "Calculating Top Companies/Positions based on groups with at least 10 employees...\n",
            "\n",
            "Top 10 Companies (by Average ctc, min size applied):\n",
            "                Company_hash_Cleaned    Avg_ctc_Co  Count_Co\n",
            "14128              nyt sqtvn wghqoto  3.215200e+07        10\n",
            "18478                          psxor  3.194560e+07        10\n",
            "36208             znn wgbbhzxwvnxgzo  2.998308e+07        13\n",
            "31033                       wrghaotp  2.819300e+07        10\n",
            "32303                 x vb v eqtoytq  2.633955e+07        22\n",
            "31167            wrvqxcvnt vzvrjnxwo  2.370000e+07        12\n",
            "32635  xeewg ngpxg stztqvr xzohqvzwt  2.065690e+07        10\n",
            "11416                 mvlvl vhng rna  1.934688e+07        16\n",
            "70                          20152019  1.882782e+07        11\n",
            "20121                       qvzaonva  1.763333e+07        12\n",
            "\n",
            "Top 2 Positions per Company (by Average ctc, min size applied):\n",
            "            Company_hash_Cleaned Job_position_Cleaned  Avg_ctc_Co_Job  \\\n",
            "48                           1bs     backend engineer    1.550526e+06   \n",
            "59                           1bs     unknown_position    1.450000e+06   \n",
            "67      1bs ntwyzgrgsxto ucn rna     unknown_position    1.441667e+06   \n",
            "62      1bs ntwyzgrgsxto ucn rna     backend engineer    1.384375e+06   \n",
            "189                        247vx     backend engineer    1.473467e+06   \n",
            "...                          ...                  ...             ...   \n",
            "70726  zxxn ntwyzgrgsxto rxbxnta     unknown_position    6.007658e+06   \n",
            "70763                  zxzlvwvqn     backend engineer    1.738824e+06   \n",
            "70770                  zxzlvwvqn     unknown_position    1.735000e+06   \n",
            "70778                  zxztrtvuo     backend engineer    1.490556e+06   \n",
            "70782                  zxztrtvuo    frontend engineer    1.096875e+06   \n",
            "\n",
            "       Count_Co_Job  \n",
            "48               19  \n",
            "59               23  \n",
            "67               12  \n",
            "62               16  \n",
            "189              15  \n",
            "...             ...  \n",
            "70726            38  \n",
            "70763            17  \n",
            "70770            12  \n",
            "70778            18  \n",
            "70782            16  \n",
            "\n",
            "[1271 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Data Processing for Unsupervised Clustering ---\n",
        "print(\"\\n--- 7. Data Processing for Unsupervised Clustering ---\")\n",
        "# Note: Clustering on high-dimensional sparse data can be challenging.\n",
        "# Results might be skewed or sensitive to feature selection and algorithm choice.\n",
        "features_for_clustering = ['ctc', 'Years_of_Experience']\n",
        "categorical_features_for_clustering = ['Company_hash_Cleaned', 'Job_position_Cleaned']\n",
        "\n",
        "# Select data and drop NaNs *before* encoding/scaling\n",
        "df_cluster = df[features_for_clustering + categorical_features_for_clustering].copy()\n",
        "df_cluster.dropna(inplace=True) # Drop rows with NaN in any selected feature\n",
        "print(f\"\\nShape of data for clustering after dropping NaNs: {df_cluster.shape}\")\n",
        "\n",
        "if df_cluster.empty:\n",
        "    print(\"No data available for clustering after dropping NaNs. Exiting clustering steps.\")\n",
        "    # Assign default values if clustering fails\n",
        "    df['KMeans_Cluster'] = -1\n",
        "    df['Hierarchical_Cluster'] = -1\n",
        "else:\n",
        "    # Separate numerical and categorical data\n",
        "    df_cluster_numeric = df_cluster[features_for_clustering]\n",
        "    df_cluster_categorical = df_cluster[categorical_features_for_clustering]\n",
        "\n",
        "    # Encode Categorical Features (Sparse)\n",
        "    print(\"\\nApplying One-Hot Encoding (Sparse)...\")\n",
        "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
        "    encoded_cats_sparse = encoder.fit_transform(df_cluster_categorical)\n",
        "    print(f\"Shape of sparse encoded categories: {encoded_cats_sparse.shape}\")\n",
        "\n",
        "    # Combine numerical and sparse categorical features\n",
        "    print(\"\\nCombining numerical and sparse categorical features...\")\n",
        "    numeric_array = df_cluster_numeric.values\n",
        "    # Ensure numeric array is 2D\n",
        "    if numeric_array.ndim == 1:\n",
        "        numeric_array = numeric_array.reshape(-1, 1)\n",
        "    df_cluster_processed_sparse = hstack((numeric_array, encoded_cats_sparse), format='csr')\n",
        "    print(f\"Shape after combining: {df_cluster_processed_sparse.shape}\")\n",
        "\n",
        "    # Standardization (Sparse)\n",
        "    print(\"\\nStandardizing combined sparse features (with_mean=False)...\")\n",
        "    scaler_cluster = StandardScaler(with_mean=False)\n",
        "    df_cluster_scaled = scaler_cluster.fit_transform(df_cluster_processed_sparse)\n",
        "    print(\"Standardization complete.\")\n",
        "    print(f\"Shape of scaled data: {df_cluster_scaled.shape}\")\n",
        "\n",
        "    # Store original indices corresponding to the scaled data\n",
        "    original_indices_scaled = df_cluster.index\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YP1LNYr6-4qp",
        "outputId": "01e55555-9ae0-4f1e-f14b-3fbd1dcf9930"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 7. Data Processing for Unsupervised Clustering ---\n",
            "\n",
            "Shape of data for clustering after dropping NaNs: (205809, 4)\n",
            "\n",
            "Applying One-Hot Encoding (Sparse)...\n",
            "Shape of sparse encoded categories: (205809, 38113)\n",
            "\n",
            "Combining numerical and sparse categorical features...\n",
            "Shape after combining: (205809, 38115)\n",
            "\n",
            "Standardizing combined sparse features (with_mean=False)...\n",
            "Standardization complete.\n",
            "Shape of scaled data: (205809, 38115)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # --- 8. Unsupervised Learning - Clustering ---\n",
        "    print(\"\\n--- 8. Unsupervised Learning - Clustering ---\")\n",
        "\n",
        "    # Sampling for Elbow Method & Hierarchical Clustering\n",
        "    df_cluster_scaled_sample = df_cluster_scaled\n",
        "    sampled_original_indices = original_indices_scaled\n",
        "\n",
        "    if df_cluster_scaled.shape[0] > SAMPLE_SIZE * 1.5:\n",
        "        print(f\"\\nSampling data down to {SAMPLE_SIZE} for efficiency...\")\n",
        "        np.random.seed(42)\n",
        "        sample_indices = np.random.choice(df_cluster_scaled.shape[0], size=SAMPLE_SIZE, replace=False)\n",
        "        df_cluster_scaled_sample = df_cluster_scaled[sample_indices, :]\n",
        "        sampled_original_indices = original_indices_scaled[sample_indices]\n",
        "        print(f\"Sampled data shape: {df_cluster_scaled_sample.shape}\")\n",
        "    else:\n",
        "        print(\"\\nDataset size small enough, not sampling.\")\n",
        "\n",
        "    print(f\"Using data of shape {df_cluster_scaled_sample.shape} for Elbow/Hierarchical.\")\n",
        "\n",
        "    # K-Means Clustering\n",
        "    print(\"\\nApplying K-Means Clustering...\")\n",
        "    print(\"Running Elbow Method (on sample)...\")\n",
        "    inertia = []\n",
        "    k_range = range(2, 11)\n",
        "    for k in k_range:\n",
        "        try:\n",
        "            kmeans = KMeans(n_clusters=k, init='k-means++', n_init=10, random_state=42)\n",
        "            kmeans.fit(df_cluster_scaled_sample)\n",
        "            inertia.append(kmeans.inertia_)\n",
        "            print(f\"  Completed K={k}, Inertia={kmeans.inertia_:.2f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Failed K={k}: {e}\")\n",
        "            inertia.append(None)\n",
        "\n",
        "    # Plot Elbow Method\n",
        "    valid_inertia = [(k, i) for k, i in zip(k_range, inertia) if i is not None]\n",
        "    if valid_inertia:\n",
        "        valid_k, valid_i = zip(*valid_inertia)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(valid_k, valid_i, marker='o')\n",
        "        plt.title('Elbow Method for Optimal K (Sampled Data)')\n",
        "        plt.xlabel('Number of Clusters (K)')\n",
        "        plt.ylabel('Inertia')\n",
        "        plt.xticks(valid_k)\n",
        "        plt.grid(True)\n",
        "        plt.savefig('kmeans_elbow_plot.png')\n",
        "        plt.close()\n",
        "        print(\"Saved Elbow Method plot as kmeans_elbow_plot.png\")\n",
        "        # Recommendation: Manually inspect kmeans_elbow_plot.png to potentially update OPTIMAL_K\n",
        "        print(f\"Recommendation: Inspect 'kmeans_elbow_plot.png' and potentially update OPTIMAL_K (currently {OPTIMAL_K}) in the script.\")\n",
        "    else:\n",
        "        print(\"Could not generate Elbow plot.\")\n",
        "\n",
        "    # Apply K-Means with chosen K on FULL scaled data\n",
        "    print(f\"\\nApplying K-Means with K={OPTIMAL_K} on full data...\")\n",
        "    # Note: K-Means on high-dimensional sparse data can lead to skewed clusters.\n",
        "    kmeans_final = KMeans(n_clusters=OPTIMAL_K, init='k-means++', n_init=10, random_state=42)\n",
        "    try:\n",
        "        kmeans_labels = kmeans_final.fit_predict(df_cluster_scaled)\n",
        "        df['KMeans_Cluster'] = pd.Series(kmeans_labels, index=original_indices_scaled)\n",
        "        df['KMeans_Cluster'].fillna(-1, inplace=True)\n",
        "        df['KMeans_Cluster'] = df['KMeans_Cluster'].astype(int)\n",
        "        print(f\"\\nK-Means clustering complete. Cluster distribution:\")\n",
        "        print(df['KMeans_Cluster'].value_counts())\n",
        "    except Exception as e:\n",
        "        print(f\"K-Means failed: {e}\")\n",
        "        df['KMeans_Cluster'] = -1\n",
        "\n",
        "\n",
        "    # Hierarchical Clustering (on sample)\n",
        "    print(\"\\nApplying Hierarchical Clustering (on sample)...\")\n",
        "    # Note: Hierarchical clustering is computationally expensive (O(n^2) or O(n^3)).\n",
        "    # Also, dendrogram plotting often requires dense matrices, which fail on large sparse data.\n",
        "    try:\n",
        "        plt.figure(figsize=(15, 7))\n",
        "        plt.title(\"Hierarchical Clustering Dendrogram (Sampled Data)\")\n",
        "        # Linkage function can sometimes handle sparse input directly\n",
        "        linked = shc.linkage(df_cluster_scaled_sample, method='ward')\n",
        "        shc.dendrogram(linked, truncate_mode='lastp', p=12, leaf_rotation=90., leaf_font_size=8., show_contracted=True) # Truncate for readability\n",
        "        plt.xlabel(\"Cluster Size (Sampled)\")\n",
        "        plt.ylabel(\"Distance\")\n",
        "        plt.savefig('hierarchical_dendrogram.png')\n",
        "        plt.close()\n",
        "        print(\"Saved Dendrogram plot as hierarchical_dendrogram.png\")\n",
        "    except MemoryError:\n",
        "        print(\"MemoryError plotting dendrogram, sample might still be too large/dense.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate Dendrogram: {e}\") # May fail if linkage doesn't support sparse\n",
        "\n",
        "    # Apply Agglomerative Clustering on sample\n",
        "    N_CLUSTERS_HIERARCHICAL = OPTIMAL_K\n",
        "    print(f\"Applying Agglomerative Clustering with {N_CLUSTERS_HIERARCHICAL} clusters (on sample)...\")\n",
        "    try:\n",
        "        agg_clustering = AgglomerativeClustering(n_clusters=N_CLUSTERS_HIERARCHICAL, linkage='ward')\n",
        "        # AgglomerativeClustering might need dense array, try converting sample if feasible\n",
        "        # Check memory footprint before converting to dense\n",
        "        sample_elements = df_cluster_scaled_sample.shape[0] * df_cluster_scaled_sample.shape[1]\n",
        "        # Estimate memory in GB (float64 is 8 bytes)\n",
        "        estimated_memory_gb = sample_elements * 8 / (1024**3)\n",
        "        print(f\"Estimated memory for dense sample conversion: {estimated_memory_gb:.2f} GB\")\n",
        "\n",
        "        if estimated_memory_gb < 4: # Set a reasonable memory threshold (e.g., 4GB)\n",
        "             print(\"Attempting Agglomerative Clustering on dense sample...\")\n",
        "             agg_labels_sample = agg_clustering.fit_predict(df_cluster_scaled_sample.toarray())\n",
        "        else:\n",
        "             print(\"Sample too large for dense conversion in AgglomerativeClustering, skipping fit.\")\n",
        "             agg_labels_sample = None\n",
        "\n",
        "        if agg_labels_sample is not None:\n",
        "            agg_cluster_series = pd.Series(agg_labels_sample, index=sampled_original_indices)\n",
        "            df['Hierarchical_Cluster'] = agg_cluster_series\n",
        "            df['Hierarchical_Cluster'].fillna(-1, inplace=True)\n",
        "            df['Hierarchical_Cluster'] = df['Hierarchical_Cluster'].astype(int)\n",
        "            print(f\"\\nHierarchical clustering complete. Cluster distribution (on sample):\")\n",
        "            print(df['Hierarchical_Cluster'].value_counts())\n",
        "        else:\n",
        "             df['Hierarchical_Cluster'] = -1\n",
        "\n",
        "    except MemoryError:\n",
        "        print(\"MemoryError during Agglomerative Clustering, sample might be too large for dense conversion.\")\n",
        "        df['Hierarchical_Cluster'] = -1\n",
        "    except Exception as e:\n",
        "        print(f\"Hierarchical clustering failed: {e}\")\n",
        "        df['Hierarchical_Cluster'] = -1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1457
        },
        "id": "GkH-xStj_RbM",
        "outputId": "c5198444-6412-4704-f021-8a893e1f8530"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 8. Unsupervised Learning - Clustering ---\n",
            "\n",
            "Sampling data down to 5000 for efficiency...\n",
            "Sampled data shape: (5000, 38115)\n",
            "Using data of shape (5000, 38115) for Elbow/Hierarchical.\n",
            "\n",
            "Applying K-Means Clustering...\n",
            "Running Elbow Method (on sample)...\n",
            "  Completed K=2, Inertia=190940808.47\n",
            "  Completed K=3, Inertia=190735226.11\n",
            "  Completed K=4, Inertia=190460357.82\n",
            "  Completed K=5, Inertia=190323604.68\n",
            "  Completed K=6, Inertia=190116663.29\n",
            "  Completed K=7, Inertia=189910643.51\n",
            "  Completed K=8, Inertia=189499196.32\n",
            "  Completed K=9, Inertia=189499745.32\n",
            "  Completed K=10, Inertia=189220762.41\n",
            "Saved Elbow Method plot as kmeans_elbow_plot.png\n",
            "Recommendation: Inspect 'kmeans_elbow_plot.png' and potentially update OPTIMAL_K (currently 5) in the script.\n",
            "\n",
            "Applying K-Means with K=5 on full data...\n",
            "\n",
            "K-Means clustering complete. Cluster distribution:\n",
            "KMeans_Cluster\n",
            "0    205801\n",
            "4         3\n",
            "3         2\n",
            "2         2\n",
            "1         1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Applying Hierarchical Clustering (on sample)...\n",
            "Could not generate Dendrogram: setting an array element with a sequence.\n",
            "Applying Agglomerative Clustering with 5 clusters (on sample)...\n",
            "Estimated memory for dense sample conversion: 1.42 GB\n",
            "Attempting Agglomerative Clustering on dense sample...\n",
            "\n",
            "Hierarchical clustering complete. Cluster distribution (on sample):\n",
            "Hierarchical_Cluster\n",
            "-1    200809\n",
            " 0      4996\n",
            " 3         1\n",
            " 2         1\n",
            " 4         1\n",
            " 1         1\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 9. Insights from Unsupervised Clustering ---\n",
        "print(\"\\n--- 9. Insights from Unsupervised Clustering ---\")\n",
        "print(\"\\nAnalyzing K-Means Cluster Characteristics (Cluster Means):\")\n",
        "# Use only rows that were successfully clustered by K-Means\n",
        "df_analysis = df.loc[df['KMeans_Cluster'] != -1].copy()\n",
        "\n",
        "if not df_analysis.empty and df['KMeans_Cluster'].nunique() > 1:\n",
        "    cluster_summary_num = df_analysis.groupby('KMeans_Cluster')[['ctc', 'Years_of_Experience']].mean()\n",
        "    print(\"\\nNumerical Feature Means per K-Means Cluster:\")\n",
        "    print(cluster_summary_num)\n",
        "\n",
        "    print(\"\\nCategorical Feature Distribution per K-Means Cluster (Top 5):\")\n",
        "    for cluster_id in sorted(df_analysis['KMeans_Cluster'].unique()):\n",
        "        print(f\"\\n--- Cluster {cluster_id} ---\")\n",
        "        cluster_data = df_analysis[df_analysis['KMeans_Cluster'] == cluster_id]\n",
        "        print(f\"Size: {len(cluster_data)} learners\")\n",
        "        # Top Companies\n",
        "        top_companies = cluster_data['Company_hash_Cleaned'].value_counts().head(5)\n",
        "        print(\"Top 5 Companies:\")\n",
        "        print(top_companies)\n",
        "        # Top Job Positions\n",
        "        top_jobs = cluster_data['Job_position_Cleaned'].value_counts().head(5)\n",
        "        print(\"\\nTop 5 Job Positions:\")\n",
        "        print(top_jobs)\n",
        "    # Add comment about potential skewness observed in output\n",
        "    print(\"\\n*Note: K-Means cluster sizes appear highly skewed. One cluster dominates, others are small.\")\n",
        "    print(\" This might indicate outliers or limitations of K-Means on this high-dimensional sparse data.\")\n",
        "    print(\" Further analysis might involve different feature scaling, feature selection, or algorithms (e.g., DBSCAN).\")\n",
        "\n",
        "else:\n",
        "    print(\"No K-Means clusters found or K-Means failed/produced only one cluster.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_AcOH8lA_fuY",
        "outputId": "0960ff1a-6804-4b70-e1f6-e6841e8b5e2d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 9. Insights from Unsupervised Clustering ---\n",
            "\n",
            "Analyzing K-Means Cluster Characteristics (Cluster Means):\n",
            "\n",
            "Numerical Feature Means per K-Means Cluster:\n",
            "                         ctc  Years_of_Experience\n",
            "KMeans_Cluster                                   \n",
            "0               2.271916e+06             9.883611\n",
            "1               1.800000e+06             7.000000\n",
            "2               3.600000e+05             6.000000\n",
            "3               6.700000e+05            11.000000\n",
            "4               1.060000e+06            16.333333\n",
            "\n",
            "Categorical Feature Distribution per K-Means Cluster (Top 5):\n",
            "\n",
            "--- Cluster 0 ---\n",
            "Size: 205801 learners\n",
            "Top 5 Companies:\n",
            "Company_hash_Cleaned\n",
            "nvnv wgzohrnvzwj otqcxwto    8337\n",
            "xzegojo                      5381\n",
            "vbvkgz                       3481\n",
            "zgn vuurxwvmrt vwwghzn       3410\n",
            "wgszxkvzn                    3240\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Top 5 Job Positions:\n",
            "Job_position_Cleaned\n",
            "unknown_position      52548\n",
            "backend engineer      43544\n",
            "fullstack engineer    25976\n",
            "other                 18070\n",
            "frontend engineer     10417\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Cluster 1 ---\n",
            "Size: 1 learners\n",
            "Top 5 Companies:\n",
            "Company_hash_Cleaned\n",
            "ojzxnx    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Top 5 Job Positions:\n",
            "Job_position_Cleaned\n",
            "cloud software engineer    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Cluster 2 ---\n",
            "Size: 2 learners\n",
            "Top 5 Companies:\n",
            "Company_hash_Cleaned\n",
            "vwn exmtqztn    2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Top 5 Job Positions:\n",
            "Job_position_Cleaned\n",
            "support engineer    1\n",
            "unknown_position    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Cluster 3 ---\n",
            "Size: 2 learners\n",
            "Top 5 Companies:\n",
            "Company_hash_Cleaned\n",
            "bvzgl exqt tihxubtzno ucn rna    2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Top 5 Job Positions:\n",
            "Job_position_Cleaned\n",
            "unknown_position    1\n",
            "other               1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Cluster 4 ---\n",
            "Size: 3 learners\n",
            "Top 5 Companies:\n",
            "Company_hash_Cleaned\n",
            "mbg exzvzwxvr sqghu    3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Top 5 Job Positions:\n",
            "Job_position_Cleaned\n",
            "backend engineer    2\n",
            "other               1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "*Note: K-Means cluster sizes appear highly skewed. One cluster dominates, others are small.\n",
            " This might indicate outliers or limitations of K-Means on this high-dimensional sparse data.\n",
            " Further analysis might involve different feature scaling, feature selection, or algorithms (e.g., DBSCAN).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 10. Save Output & Recommendations ---\n",
        "output_file = 'scaler_clustered_data.csv'\n",
        "print(f\"\\n--- 10. Saving processed data to {output_file}... ---\")\n",
        "try:\n",
        "    # Ensure float columns don't have excessive precision causing large file sizes\n",
        "    float_cols = df.select_dtypes(include=['float']).columns\n",
        "    for col in float_cols:\n",
        "        df[col] = df[col].round(4) # Round floats to reasonable precision\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(\"File saved successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving file: {e}\")\n",
        "\n",
        "print(\"\\n--- Actionable Insights & Recommendations ---\")\n",
        "# Recommendations remain largely the same structure, but interpretation depends on actual cluster results\n",
        "print(f\"\"\"\n",
        "Based on the analysis (interpret actual results from the run):\n",
        "\n",
        "**Insights:**\n",
        "\n",
        "1.  **Learner Segmentation:** K-Means clustering (K={OPTIMAL_K}) was performed, but resulted in highly unbalanced clusters (check console output/CSV). One cluster likely contains the vast majority of learners, while others capture outliers or very small groups. This limits the usefulness of these specific K-Means clusters for broad segmentation. Manual flags provide more practical segmentation for now.\n",
        "2.  **Manual vs. Unsupervised:** The manual flags (Tier, Class, Designation) provide valuable insights into relative compensation within specific peer groups (Company, Job, Experience). These are likely more reliable for targeted actions than the current K-Means results. Compare flags and K-Means labels in `scaler_clustered_data.csv`.\n",
        "3.  **Company/Role Attractiveness:** Top companies and roles were identified based on average CTC (filtered for minimum group size). Review the console output for these rankings. Be mindful of potential CTC outliers influencing averages.\n",
        "4.  **Experience-ctc Correlation:** A positive correlation generally exists (see `bivariate_exp_ctc.png`), though log-scaling was needed for visualization due to CTC skewness. Manual flags help understand variations within specific experience levels.\n",
        "5.  **Data Quality:** Issues noted include invalid `orgyear` values (handled by capping experience) and potential extreme outliers in `ctc`, which impact analysis.\n",
        "\n",
        "**Recommendations for Scaler:**\n",
        "\n",
        "1.  **Leverage Manual Flags:** Use the Tier, Class, and Designation flags for targeted career services, salary benchmarking, and identifying upskilling opportunities, as the unsupervised clusters were not well-balanced.\n",
        "2.  **Curriculum Enhancement:** Analyze job roles associated with Tier 1 / Class 1 employees and ensure curriculum alignment.\n",
        "3.  **Employer Partnerships:** Focus on companies identified as 'top employers' (considering average CTC and employee count).\n",
        "4.  **Future Analysis:**\n",
        "    *   Investigate and clean/handle CTC outliers more formally (e.g., capping, log transform *before* clustering).\n",
        "    *   Explore alternative clustering algorithms suitable for high-dimensional sparse data (e.g., DBSCAN, Birch) or dimensionality reduction techniques (e.g., PCA, TruncatedSVD) before clustering.\n",
        "    *   Refine feature engineering/selection for unsupervised clustering.\n",
        "    *   Manually inspect the elbow plot (`kmeans_elbow_plot.png`) to confirm if K={OPTIMAL_K} is appropriate or if a different K should be chosen.\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n--- Analysis Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3pdH65k-_jgv",
        "outputId": "6c08f3e4-e96d-472a-b675-f651c7117877"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 10. Saving processed data to scaler_clustered_data.csv... ---\n",
            "File saved successfully.\n",
            "\n",
            "--- Actionable Insights & Recommendations ---\n",
            "\n",
            "Based on the analysis (interpret actual results from the run):\n",
            "\n",
            "**Insights:**\n",
            "\n",
            "1.  **Learner Segmentation:** K-Means clustering (K=5) was performed, but resulted in highly unbalanced clusters (check console output/CSV). One cluster likely contains the vast majority of learners, while others capture outliers or very small groups. This limits the usefulness of these specific K-Means clusters for broad segmentation. Manual flags provide more practical segmentation for now.\n",
            "2.  **Manual vs. Unsupervised:** The manual flags (Tier, Class, Designation) provide valuable insights into relative compensation within specific peer groups (Company, Job, Experience). These are likely more reliable for targeted actions than the current K-Means results. Compare flags and K-Means labels in `scaler_clustered_data.csv`.\n",
            "3.  **Company/Role Attractiveness:** Top companies and roles were identified based on average CTC (filtered for minimum group size). Review the console output for these rankings. Be mindful of potential CTC outliers influencing averages.\n",
            "4.  **Experience-ctc Correlation:** A positive correlation generally exists (see `bivariate_exp_ctc.png`), though log-scaling was needed for visualization due to CTC skewness. Manual flags help understand variations within specific experience levels.\n",
            "5.  **Data Quality:** Issues noted include invalid `orgyear` values (handled by capping experience) and potential extreme outliers in `ctc`, which impact analysis.\n",
            "\n",
            "**Recommendations for Scaler:**\n",
            "\n",
            "1.  **Leverage Manual Flags:** Use the Tier, Class, and Designation flags for targeted career services, salary benchmarking, and identifying upskilling opportunities, as the unsupervised clusters were not well-balanced.\n",
            "2.  **Curriculum Enhancement:** Analyze job roles associated with Tier 1 / Class 1 employees and ensure curriculum alignment.\n",
            "3.  **Employer Partnerships:** Focus on companies identified as 'top employers' (considering average CTC and employee count).\n",
            "4.  **Future Analysis:**\n",
            "    *   Investigate and clean/handle CTC outliers more formally (e.g., capping, log transform *before* clustering).\n",
            "    *   Explore alternative clustering algorithms suitable for high-dimensional sparse data (e.g., DBSCAN, Birch) or dimensionality reduction techniques (e.g., PCA, TruncatedSVD) before clustering.\n",
            "    *   Refine feature engineering/selection for unsupervised clustering.\n",
            "    *   Manually inspect the elbow plot (`kmeans_elbow_plot.png`) to confirm if K=5 is appropriate or if a different K should be chosen.\n",
            "\n",
            "\n",
            "\n",
            "--- Analysis Complete ---\n"
          ]
        }
      ]
    }
  ]
}